---
title: "Exam in Multivariate Statistics"
author: "Eirikur Jonsson"
date: "14/05/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(st514)
#library(tidyverse)
library(ggplot2)
library(GGally)
library(corrplot)
library(ggcorrplot)
library(MASS)
library(rcompanion)
library(cowplot)
data("T1-6")
df <- tbl
# Non-multiple-sclerosis (NMS) group data
nms <- subset(df, V6 == 0)
# Multiple-sclerosis (MS) group data
ms <- subset(df, V6 == 1)
```

# Co/Variance matrix

```{r}
coVar <- function(x){
  v <- cov(x) * (nrow(x) -1) / nrow(x)
  return(v)
}
print("No-Multiple-Sclerosis")
print(coVar(nms[1:5]))
print("Multiple-Sclerosis")
print(coVar(ms[1:5]))
```

# Pure Variance Matrix

```{r}
print("Not-Multiple-Sclerosis")
print(var(nms[1:5]))
print("Multiple-Sclerosis")
print(var(ms[1:5]))
```

# Mean Vectors

```{r}
print("Not-Multiple-Sclerosis")
print(colMeans(nms[1:5]))
print("Multiple-Sclerosis")
print(colMeans(ms[1:5]))
```

# Std for each column

```{r}
msStd <- apply(ms[1:5], 2, sd)
nmsStd <- apply(nms[1:5], 2, sd)
print(msStd)
print(nmsStd)

```


# Plotting


```{r}
corMatrix <- cor(ms[1:5])
p_corMat <- cor_pmat(ms[1:5])

#ggpairs(ms[2:5], progress = FALSE)
ggpairs(nms[1:5], progress = FALSE)
```
```{r}
corrplot(cor(nms[1:5]), method = "ellipse", main = "Non MS")
corrplot(cor(ms[1:5]), method  = "ellipse", main = "MS")
```

```{r}
pairs(nms[1:5], diag.panel = panel.boxplot, labels = "", main = "Non MS")
pairs(ms[1:5], diag.panel = panel.boxplot, labels = "", main = "MS")
```

# Descriptive function

```{r}
descriptive <- function(x){
  "
  This function takes in one input parameter
  and that is a dataframe or matrix
  
  The output of this function will be
  
  1. Mean for each column in the dataset
  2. Covariance matrix
  3. Co/Variance Matrix
  4. Variance matrix
  5. Inverse of the covariance matrix
  6. Determinant of the covariance matrix
  "
  xmean <- colMeans(x)
  xcov <- cov(x)
  xcovVar <- cov(x) * (nrow(x) -1) / nrow(x)
  xvar <- var(x)
  xcovInv <- solve(xcov)
  xdet <- det(xcov)

  # Debug block
  
  # print("Mean Vector")
  # print(xmean)
  # print("-----------------------------------------------------")
  # print("Covariance")
  # print(xcov)
  # print("-----------------------------------------------------")
  # print("Xco/Variance")
  # print(xcovVar)
  # print("-----------------------------------------------------")
  # print("Variance")
  # print(xvar)
  # print("-----------------------------------------------------")
  # print("Covariance inverse")
  # print(xcovInv)
  # print("-----------------------------------------------------")
  # print("Determinant")
  # print(xdet)
  mylist = list("meanVector" = xmean, "Covariance" = xcov, "Co-Variance" = xcovVar, "Variance" = xvar, "CovInverse" = xcovInv, "Determinant" = xdet)
  return(mylist)
}
descriptive(nms[2:5])
```


# Testing multivariate mean vector with $T^2$

What is needed:

- Mean vector
- Hypo-means
- Covariance matrix
- Inverse of covariance matrix

```{r}
tsqared <- function(x,y,f){
  n <- nrow(x)
  xmean <- colMeans(x)
  xcov <- cov(x)
  xcovin <- solve(xcov)
  xyvar <- xmean - y
  p1 <- xyvar %*% xcovin
  result <- round(p1%*%(n*xyvar),3)
  fstat <- qf(f, df1 = ncol(x), df2 = nrow(x)-ncol(x))
  if(result > fstat){
    print("We REJECT the Null Hypothesis that y is a possible mean vector in x")
  }else{
    print("We ACCEPT the Null Hypothesis and y is a possible mean vector in x")
  }
  return(c(result, fstat))
}
```

```{r}
nmsM <- colMeans(nms[1:5])
msM <- colMeans(ms[1:5])
print("For the MS dataset using the Non-MS mean-vector")
print(tsqared(x=ms[1:5], y=nmsM, f=0.9))
print("For the Non-MS dataset using the MS mean-vector")
print(tsqared(x = nms[1:5], y = msM, f = 0.9))
```

# Box-Cox tranformation
```{r}
nBoxCox <- function(x){
box <- boxcox(x ~1, lambda = seq(-20,20,0.1))
Cox <- data.frame(box$x, box$y)
Cox2 <- Cox[with(Cox, order(-Cox$box.y)),]
Cox2[1,]
lambda = Cox2[1,"box.x"]
df_box <- (x ^ lambda - 1)/lambda
plotNormalHistogram(df_box)
nShapiro <- shapiro.test(df_box)
nList <- list("Results" = df_box, "Shapiro-Wilk Test" = nShapiro)
return(nList)
}
```
```{r}
v2msBox <- nBoxCox(ms$V2)
v2msBoxTrans <- v2msBox$Results
v2msBoxTrans <- data.frame(v2msBoxTrans)
qqnorm(v2msBoxTrans[,1])
qqline(v2msBoxTrans[,1])
print(v2msBox$`Shapiro-Wilk Test`)
```
```{r}
v2nmsBox <- nBoxCox(nms$V2)
v2nmsBoxTrans <- v2nmsBox$Results
v2nmsBoxTrans <- data.frame(v2nmsBoxTrans)
qqnorm(v2nmsBoxTrans[,1])
qqline(v2nmsBoxTrans[,1])
print(v2nmsBox$`Shapiro-Wilk Test`)
```
```{r}
plot(density(v2msBox$Results))
plot(density(v2nmsBox$Results))
?log
```


## Original variables are normally distributed.
```{r}
shapiro.test(ms$V2)
shapiro.test(nms$V2)
```

<<<<<<< HEAD
# Principal component analysis and combination

We wanted to see if the variables were measuring the same latent variable so we ran a principal component analysis to see if this was the case. We decided to maximize the factor-loadings onto each factor so we used varimax rotation and since we are hoping that there are only two principal components we then give the principal()function only 2 factors to look for. This function will also tell us if two factor were sufficient.

```{r}
df <- tbl[2:5]
pcamodel <- principal(df, nfactors = 2, rotate = "varimax")
print(summary(pcamodel))
print(pcamodel$loadings)
```

As the PCA model results show V2 and V4 are measuring the same latent variable and that V3 and V5 do the same on a different variable. We will therefor combine these variables into two variables that will allow for a simpler model building and easier to interperate results from our eventual classification. To combine these variables we will use the Euclidian Distance between the two variables. This means the eucliduan distance between V2 - V4 and then V3 - V5. To simplify we construct a function called euclid.

```{r}
euclid <- function(x,y){
  "
  This function calculates the euclidian distance between two variables
  "
  dist <- sqrt((x - y)^2)
  return(dist)
}

tbl$V24 <- euclid(tbl$V2, tbl$V4)
tbl$V35 <- euclid(tbl$V3, tbl$V4)
par(mfrow = c(1,2))
plot(density(tbl$V24))
plot(density(tbl$V35))
  
```

From those two plots we can see that the variables are not gaussian, but lets look at them individually between the MS and NMS groups.

```{r}
nms <- subset(tbl, V6 == 0)
ms <- subset(tbl, V6 == 1)

par(mfrow = c(2,2))
plot(density(nms$V24))
plot(density(nms$V35))
plot(density(ms$V24))
plot(density(ms$V35))
```


```{r}
dV24ms <- density(ms$V24)
dV24nms <- density(nms$V24)

dV35ms <- density(ms$V35)
dV35nms <- density(nms$V35)

V24msX <- dV24ms$x
V24msY <- dV24ms$y
V24nmsX <- dV24nms$x
V24nmsY <- dV24nms$y

V35msX <- dV35ms$x
V35msY <- dV35ms$y
V35nmsX <- dV35nms$x
V35nmsY <- dV35nms$y

df2 <- data.frame(V24msX, V24msY, V35msX, V35msY)
df3 <- data.frame(V24nmsX, V24nmsY, V35nmsX, V35nmsY)

ggplot()+
  geom_line(aes(x = df2$V24msX, y = df2$V24msY), color = "red")+
  geom_line(aes(x = df3$V24nmsX, y = df3$V24nmsY), color = "pink")+
  geom_line(aes(x = df2$V35msX, y = df2$V35msY), color = "blue")+
  geom_line(aes(x = df3$V35nmsX, y = df3$V35nmsY), color = "steelblue")

```


```{r}
model <- manova(cbind(V24,V35) ~ V6, data = tbl)
summary(model)
```



```{r}
transV24 <- nBoxCox(tbl$V24)
transV35 <- nBoxCox(tbl$V35)
shapiro.test(transV24$Results)
shapiro.test(transV35$Results)

dtransV24 <- density(transV24$Results)
dtransV35 <- density(transV35$Results)

dtransV24X <- dtransV24$x
dtransV24Y <- dtransV24$y
dtransV35X <- dtransV35$x
dtransV35Y <- dtransV35$y

df4 <- data.frame(dtransV24X, dtransV24Y, dtransV35X, dtransV35Y)

v24plot <- ggplot()+
  geom_line(aes(x = df4$dtransV24X, y = df4$dtransV24Y))
v35plot <- ggplot()+
  geom_line(aes(x = df4$dtransV35X, y = df4$dtransV35Y))
plot_grid(v24plot, v35plot, labels = "AUTO")
```

```{r}
tbl$transV24 <- transV24$Results
tbl$transV35 <- transV35$Results

nms <- subset(tbl, V6 == 0)
ms <- subset(tbl, V6 == 1)

par(mfrow = c(2,2))
plot(density(nms$transV24))
plot(density(nms$transV35))
plot(density(ms$transV24))
plot(density(ms$transV35))
```

```{r}
print(shapiro.test(tbl$transV24))
print("--------------------------")
print(shapiro.test(tbl$transV35))
print("--------------------------")
print(shapiro.test(ms$transV24))
print("--------------------------")
print(shapiro.test(ms$transV35))
print("--------------------------")
print(shapiro.test(nms$transV24))
print("--------------------------")
print(shapiro.test(nms$transV35))
```





































=======
Hi my name is stupid - I live in a gallery - see my army of statues out there - they scare me and they are creepy
>>>>>>> 773107201b6926479e6f543bb2d0c9131017fe5b
